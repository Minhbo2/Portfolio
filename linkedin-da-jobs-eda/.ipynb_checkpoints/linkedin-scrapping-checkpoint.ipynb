{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4fc812-4908-42a8-9095-7126dcc2e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21270a07-bc16-41f4-a04f-3c1a3b52cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd0848f4-ce6b-4f1b-b569-842f36248117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make to download the correct chrome driver, update path to its directory\n",
    "wd = webdriver.Chrome(executable_path='./chromedriver.exe')\n",
    "url = 'https://www.linkedin.com/jobs/search?keywords=Data%20Analyst&location=Oakland%2C%20California%2C%20United%20States&geoId=105883676&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0'\n",
    "wd.get(url)\n",
    "wd.maximize_window()\n",
    "\n",
    "no_of_jobs = wd.find_element_by_css_selector('h1>span').get_attribute('innerText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "950f64df-b695-46c7-b32e-8a76f7e2d6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert str result of job counts into int\n",
    "no_of_jobs_str = no_of_jobs\n",
    "no_of_jobs_str = no_of_jobs_str[:-1]\n",
    "no_of_jobs_int = int(no_of_jobs_str.replace(',',''))\n",
    "no_of_jobs_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c373200a-69c9-4984-a277-e979387e5b2d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# expanding the listing to get a total of no_of_jobs_in posts\n",
    "i = 2\n",
    "\n",
    "# while i <= int(no_of_jobs_int/25) + 1:\n",
    "while i <= int(1000/25) + 1: # just want about 1000 postings\n",
    "    wd.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    i = i+1\n",
    "    try:\n",
    "        wd.find_element_by_class_name('infinite-scroller__show-more-button.infinite-scroller__show-more-button').click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        pass\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35a16f33-39fe-48e8-b4f5-bd81ebd548f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of jobs\n",
    "job_lists = wd.find_element_by_class_name('jobs-search__results-list')\n",
    "jobs = job_lists.find_elements_by_tag_name('li')\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9f78ff8-f82c-40f7-aec9-27b99cf2e836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'company_name', 'city', 'state', 'link'], dtype='object')\n",
      "[2718722753, 2734867282, 2728555002, 2739437755, 2738133559, 2683775201, 2723336136, 2745545262, 2734415779, 2731831828, 2727464592, 2739455476, 2739493055, 2726826360, 2710966299, 2705924921, 2746906029, 2739479364, 2746267050, 2718613505, 2713072509, 2652785021, 2746949038, 2710303258, 2684696582]\n"
     ]
    }
   ],
   "source": [
    "# load up existing df is there is one\n",
    "job_id = []\n",
    "job_title = []\n",
    "company_name = []\n",
    "city = []\n",
    "state = []\n",
    "\n",
    "job_df = pd.read_csv('jobs.csv')\n",
    "print(job_df.columns)\n",
    "\n",
    "job_id = job_df['id'].values.tolist()\n",
    "job_title = job_df['title'].values.tolist()\n",
    "company_name = job_df['company_name'].values.tolist()\n",
    "city = job_df['city'].values.tolist()\n",
    "state = job_df['state'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37d026b3-333a-4212-9acf-a58fb1339852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "location = []\n",
    "# job_link = []\n",
    "\n",
    "for job in jobs:\n",
    "    \n",
    "    # click on each li ele to populate the job card \n",
    "    job.click()\n",
    "    \n",
    "    show_more_button = wd.find_element_by_class_name('show-more-less-html__button')\n",
    "    if len(show_more_button.text) < 1:\n",
    "        continue\n",
    "    \n",
    "    # get the job id from the url query, if already exist, skip\n",
    "    url_parts = wd.current_url.split('JobId=')\n",
    "    if not url_parts[1] in job_id:\n",
    "        job_id.append(url_parts[1])\n",
    "    \n",
    "    #     # get job title\n",
    "    #     title = job.find_element_by_css_selector('div>h3')\n",
    "    #     job_title.append(title.text)\n",
    "\n",
    "    #     # get the company name\n",
    "    #     company = job.find_element_by_css_selector('div>h4')\n",
    "    #     company_name.append(company.text)\n",
    "\n",
    "    #     # job location\n",
    "    #     job_location = job.find_element_by_class_name('job-search-card__location')\n",
    "    #     location.append(job_location.text)\n",
    "\n",
    "        # hyper link to job post\n",
    "    #     try:\n",
    "    #         # majority of the li cards have tag div with the same class name\n",
    "    #         href = job.find_element_by_class_name('base-card__full-link')\n",
    "    #     except:\n",
    "    #         # some card doesnt have the a tag with class different name\n",
    "    #         href = job.find_element_by_css_selector('li>a')\n",
    "    #         pass\n",
    "    #     job_link.append(href.get_attribute('href'))\n",
    "\n",
    "    print(len(job_id))\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e58617-4b66-4f9a-947d-00bc13436b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrubbing null values for job level\n",
    "missing_seniority_level = seniority_level\n",
    "missing_seniority_level = [i if len(i) > 0 else 'Not Applicable' for i in seniority_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cf91ce1-0f9d-4b7c-9d53-fcb1e6e40e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate city and state\n",
    "state = []\n",
    "city = []\n",
    "\n",
    "for i in range(len(location)):\n",
    "    state.append(location[i][-2:])\n",
    "    city.append(location[i][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c2b37da-29da-49ec-802f-e57fc1959fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing , in company name, just personal ref\n",
    "cleaned_company_name = [name.replace(',','-') for name in company_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec6c9d2-6d7c-46d5-b2f9-69d635c278a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.DataFrame()\n",
    "\n",
    "job_dict = {\n",
    "    'id': job_id,\n",
    "    'title': job_title,\n",
    "    'company_name': cleaned_company_name,\n",
    "    'city': city,\n",
    "    'state': state\n",
    "#     'link': job_link\n",
    "}\n",
    "\n",
    "job_df = pd.DataFrame(job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ec2b0bb-0f53-4e3f-ad4f-ae64c772dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# description, combine all substirngs into a giant string\n",
    "# sql, python, R, Tableau, BI, excel, looker, powerpoint, SAS, ETL, Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9283d5-1e7f-4354-a85d-956730d45a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
